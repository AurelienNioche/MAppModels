{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c900d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import FloatSlider, interact\n",
    "from scipy.optimize import minimize\n",
    "from types import SimpleNamespace as Namespace\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa164cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gp\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21950ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format='retina'\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e44151",
   "metadata": {},
   "source": [
    "# Active inference walking objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e530ad63",
   "metadata": {},
   "source": [
    "We model the number of step for each interval $\\Delta t$ (e.g. 5 min) with a Gaussian process that takes as input the context $c$. We then can compute estimate the number of total time step in the day, mean + SD. We can express the preference as a Gaussian distribution centered around the goal. \n",
    "\n",
    "Problem: it would be penalized if we expect more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0e6acf",
   "metadata": {},
   "source": [
    "Find $Q^*(\\pi)$ s.t. the Expected Free Energy, $\\mathcal{G} = - \\mathbb E_{Q ( o_{t:T}, z_{t:T}, \\pi )}\\left[ \\ln Q(z_{t:T} \\mid \\pi ) - \\ln \\tilde p(o_{t:T}, z_{t: T}) \\right]$, is minimized, and, interestingly:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bf7a68",
   "metadata": {},
   "source": [
    "$Q(\\pi) = \\sum_{t}^{T} \\mathbb E_{Q(o_t, z_t \\mid \\pi)} \\left[\\ln Q(z_t \\mid \\pi) - \\ln \\tilde p(o_t, z_t) \\right] = \\sum_{t}^{T}  \\underbrace{ \\mathbb E_{Q(o_t, z_t \\mid \\pi)} D_{KL}\\left[ Q(z_t \\mid o_t, \\pi) || Q(z_t \\mid \\pi) \\right] }_{ \\text{epistemic value} } + \\underbrace{ \\mathbb E_{Q(o_t \\mid \\pi) } \\left[ \\ln \\tilde p(o_t) \\right]}_{ \\text{pragmatic value} } $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9391094d",
   "metadata": {},
   "source": [
    "# Open questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5987741d",
   "metadata": {},
   "source": [
    "How to think the input of the model? What is a data point made of?\n",
    "\n",
    "For instance, if we give the time since the last reward, we might completely miss the point if what modulates the behavior is the surprise that comes with the reward: in this case, we need to have an information about the distribution of the rewards. \n",
    "\n",
    "If we give the sufficient parameters of the reward distribution, it might create difficulties when we are updating the policy, as what we might observe after a change is probably still an effect from the previous policy. Also, if we think about the true generative model being actually function of the distance to the reward, it won't be possible to learn that correctly only from the sufficient parameters. In general, it seems doubtful to no be able to call what could be a candidate generative model with the same arguments as for the predictive model that we are training for.\n",
    "\n",
    "We could give the rewards placements over the day. One difficulty then is to maintain the input size constant. One idea could be to give a very (very) long array of boolean, with each element stating the presence/absence of reward. Another could be \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744cf142",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
